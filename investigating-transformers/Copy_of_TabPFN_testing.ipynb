{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8makQgMNjM3",
        "outputId": "d99d3c1c-89a4-4b74-f3d0-308c0ef4973e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Full dataset shape: (15000, 22)\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Step 1: Load Full Dataset\n",
        "# ===========================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/datasets/stroke_prediction_dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Full dataset shape:\", data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️⃣ Install TabPFN\n",
        "!pip install tabpfn --quiet"
      ],
      "metadata": {
        "id": "ABX9Yj8rSE0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc2dae6-8f01-409d-b065-63baad006b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3️⃣ Load Dataset\n",
        "import pandas as pd\n",
        "data_path = \"/content/drive/My Drive/datasets/stroke_prediction_dataset.csv\"\n",
        "df = pd.read_csv(data_path)"
      ],
      "metadata": {
        "id": "EJl75uk5SQKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview dataset\n",
        "print(df.head())\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "# 4️⃣ Define Features & Target\n",
        "target_col = \"Diagnosis\"  # Assuming this is the label column\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Encode categorical features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Aibdo5SWtJ",
        "outputId": "6f92db84-dfb8-4b5d-ee21-351db39ef79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Patient ID       Patient Name  Age Gender  Hypertension  Heart Disease  \\\n",
            "0       18153    Mamooty Khurana   56   Male             0              1   \n",
            "1       62749  Kaira Subramaniam   80   Male             0              0   \n",
            "2       32145      Dhanush Balan   26   Male             1              1   \n",
            "3        6154        Ivana Baral   73   Male             0              0   \n",
            "4       48973  Darshit Jayaraman   51   Male             1              1   \n",
            "\n",
            "  Marital Status      Work Type Residence Type  Average Glucose Level  ...  \\\n",
            "0        Married  Self-employed          Rural                 130.91  ...   \n",
            "1         Single  Self-employed          Urban                 183.73  ...   \n",
            "2        Married   Never Worked          Rural                 189.00  ...   \n",
            "3        Married   Never Worked          Urban                 185.29  ...   \n",
            "4       Divorced  Self-employed          Urban                 177.34  ...   \n",
            "\n",
            "     Alcohol Intake Physical Activity Stroke History Family History of Stroke  \\\n",
            "0    Social Drinker          Moderate              0                      Yes   \n",
            "1             Never               Low              0                       No   \n",
            "2            Rarely              High              0                      Yes   \n",
            "3  Frequent Drinker          Moderate              0                       No   \n",
            "4            Rarely               Low              0                      Yes   \n",
            "\n",
            "   Dietary Habits Stress Levels Blood Pressure Levels  Cholesterol Levels  \\\n",
            "0           Vegan          3.48               140/108   HDL: 68, LDL: 133   \n",
            "1           Paleo          1.73                146/91    HDL: 63, LDL: 70   \n",
            "2           Paleo          7.31                154/97    HDL: 59, LDL: 95   \n",
            "3           Paleo          5.35                174/81   HDL: 70, LDL: 137   \n",
            "4     Pescatarian          6.84                121/95    HDL: 65, LDL: 68   \n",
            "\n",
            "                                            Symptoms  Diagnosis  \n",
            "0                      Difficulty Speaking, Headache     Stroke  \n",
            "1    Loss of Balance, Headache, Dizziness, Confusion     Stroke  \n",
            "2                                Seizures, Dizziness     Stroke  \n",
            "3  Seizures, Blurred Vision, Severe Fatigue, Head...  No Stroke  \n",
            "4                                Difficulty Speaking     Stroke  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "Shape: (15000, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Initial Cleanup\n",
        "cols_to_drop = ['Patient ID', 'Patient Name']\n",
        "for col in cols_to_drop:\n",
        "    if col in data.columns:\n",
        "        data.drop(columns=[col], inplace=True)"
      ],
      "metadata": {
        "id": "uXzZ77cmNy0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate numerical and categorical columns\n",
        "import numpy as np\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Fill missing values\n",
        "# Numerical: KNN Imputer\n",
        "from sklearn.impute import KNNImputer\n",
        "num_imputer = KNNImputer(n_neighbors=5)\n",
        "data[num_cols] = num_imputer.fit_transform(data[num_cols])\n",
        "\n",
        "# Categorical: fill with mode\n",
        "for col in cat_cols:\n",
        "    data[col] = data[col].fillna(data[col].mode()[0])\n",
        "\n",
        "# Step 5: Feature Engineering (Optional but improves accuracy)\n",
        "# Example: age groups and interaction feature\n",
        "if 'Age' in data.columns:\n",
        "    data['Age_group'] = pd.cut(data['Age'], bins=[0,30,50,70,100], labels=[1,2,3,4]).astype(int)\n",
        "    cat_cols = cat_cols.tolist() + ['Age_group'] # Add Age_group to categorical columns\n",
        "if 'Hypertension' in data.columns and 'Age' in data.columns:\n",
        "    data['Hypertension_x_Age'] = data['Hypertension'] * data['Age']\n",
        "    # Decide if 'Hypertension_x_Age' should be treated as categorical or numerical based on its values.\n",
        "    # Since it's a product, likely numerical, so not adding to cat_cols here.\n",
        "\n",
        "# Step 4: Encode Categorical Features (Target Encoding) - Moved after feature engineering\n",
        "from category_encoders import TargetEncoder\n",
        "target_col = 'Diagnosis'\n",
        "te = TargetEncoder()\n",
        "data[cat_cols] = te.fit_transform(data[cat_cols], data[target_col])\n",
        "\n",
        "\n",
        "# Step 6: Separate Features and Target\n",
        "X = data.drop(target_col, axis=1)\n",
        "y = data[target_col]\n",
        "\n",
        "# Step 7: Handle Class Imbalance with SMOTENC\n",
        "# Identify categorical feature indices in the data *before* scaling\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "categorical_indices = [X.columns.get_loc(col) for col in cat_cols if col in X.columns]\n",
        "smote_nc = SMOTENC(categorical_features=categorical_indices, random_state=42)\n",
        "X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
        "\n",
        "print(\"Original shape:\", X.shape, y.value_counts())\n",
        "print(\"Resampled shape:\", X_resampled.shape, np.bincount(y_resampled))\n",
        "\n",
        "# Step 8: Scale Features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "\n",
        "\n",
        "# Step 9: Train/Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled_scaled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c53j2hKXNzam",
        "outputId": "eea86600-19d3-4944-bbd6-882c4e352714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (15000, 21) Diagnosis\n",
            "0.0    7532\n",
            "1.0    7468\n",
            "Name: count, dtype: int64\n",
            "Resampled shape: (15064, 21) [7532 7532]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "e56086d4",
        "outputId": "f2120c61-9ba5-4bed-9284-a581ac20e346"
      },
      "source": [
        "from tabpfn import TabPFNClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the pre-trained TabPFN model\n",
        "# TabPFN loads a pretrained model by default when initialized\n",
        "# Make sure you have the correct model file downloaded,\n",
        "# the library handles this automatically on first use or you can specify model_path\n",
        "pretrained_model = TabPFNClassifier(device='cpu') # Using 'cpu' for broader compatibility\n",
        "\n",
        "# Apply the model to the test set\n",
        "# The model expects numpy arrays, and the features should be scaled, which X_test already is\n",
        "predictions = pretrained_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "report = classification_report(y_test, predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "This TabPFNClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-184814285.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Apply the model to the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# The model expects numpy arrays, and the features should be scaled, which X_test already is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tabpfn/classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mNumPy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \"\"\"\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label_encoder_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_encoder_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tabpfn/classifier.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \"\"\"\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0mproba_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tabpfn/classifier.py\u001b[0m in \u001b[0;36m_raw_predict\u001b[0;34m(self, X, return_logits)\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreturn_logits\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \"\"\"\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifferentiable_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This TabPFNClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418acd6d",
        "outputId": "2da010c0-4d51-4821-957a-7d56c96e77f2"
      },
      "source": [
        "!pip install category_encoders --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    }
  ]
}