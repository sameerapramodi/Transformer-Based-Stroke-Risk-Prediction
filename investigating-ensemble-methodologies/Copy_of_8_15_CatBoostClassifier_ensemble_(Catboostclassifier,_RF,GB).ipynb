{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Final Estimator: This is the model that takes the predictions of the base estimators as input and makes the final prediction. In your code, the final estimator is another CatBoostClassifier."
      ],
      "metadata": {
        "id": "KWiNZMJ2nxAZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfO18iD6ipmI",
        "outputId": "e33d49fa-fb22-421a-c797-f39311c9c9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Full dataset shape: (15000, 22)\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Step 1: Load Full Dataset\n",
        "# ===========================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/datasets/stroke_prediction_dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Full dataset shape:\", data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Advanced Stroke Prediction Pipeline\n",
        "# =========================\n",
        "\n",
        "# Step 1: Load Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from category_encoders import TargetEncoder\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "file_path = '/content/drive/My Drive/datasets/stroke_prediction_dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 3: Initial Cleanup\n",
        "cols_to_drop = ['Patient ID', 'Patient Name']\n",
        "for col in cols_to_drop:\n",
        "    if col in data.columns:\n",
        "        data.drop(columns=[col], inplace=True)"
      ],
      "metadata": {
        "id": "fsCaSZ5UjWFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 3: Initial Cleanup\n",
        "cols_to_drop = ['Patient ID', 'Patient Name']\n",
        "for col in cols_to_drop:\n",
        "    if col in data.columns:\n",
        "        data.drop(columns=[col], inplace=True)\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Fill missing values\n",
        "# Numerical: KNN Imputer\n",
        "num_imputer = KNNImputer(n_neighbors=5)\n",
        "data[num_cols] = num_imputer.fit_transform(data[num_cols])\n",
        "\n",
        "# Categorical: fill with mode\n",
        "for col in cat_cols:\n",
        "    data[col] = data[col].fillna(data[col].mode()[0])\n",
        "\n",
        "# Step 5: Feature Engineering (Optional but improves accuracy)\n",
        "# Example: age groups and interaction feature\n",
        "if 'Age' in data.columns:\n",
        "    data['Age_group'] = pd.cut(data['Age'], bins=[0,30,50,70,100], labels=[1,2,3,4]).astype(int)\n",
        "    cat_cols = cat_cols.tolist() + ['Age_group'] # Add Age_group to categorical columns\n",
        "if 'Hypertension' in data.columns and 'Age' in data.columns:\n",
        "    data['Hypertension_x_Age'] = data['Hypertension'] * data['Age']\n",
        "    # Decide if 'Hypertension_x_Age' should be treated as categorical or numerical based on its values.\n",
        "    # Since it's a product, likely numerical, so not adding to cat_cols here.\n",
        "\n",
        "# Step 4: Encode Categorical Features (Target Encoding) - Moved after feature engineering\n",
        "target_col = 'Diagnosis'\n",
        "te = TargetEncoder()\n",
        "data[cat_cols] = te.fit_transform(data[cat_cols], data[target_col])\n",
        "\n",
        "\n",
        "# Step 6: Separate Features and Target\n",
        "X = data.drop(target_col, axis=1)\n",
        "y = data[target_col]\n",
        "\n",
        "# Step 7: Handle Class Imbalance with SMOTENC\n",
        "# Identify categorical feature indices in the data *before* scaling\n",
        "categorical_indices = [X.columns.get_loc(col) for col in cat_cols if col in X.columns]\n",
        "smote_nc = SMOTENC(categorical_features=categorical_indices, random_state=42)\n",
        "X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
        "\n",
        "print(\"Original shape:\", X.shape, y.value_counts())\n",
        "print(\"Resampled shape:\", X_resampled.shape, np.bincount(y_resampled))\n",
        "\n",
        "# Step 8: Scale Features\n",
        "scaler = StandardScaler()\n",
        "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "\n",
        "\n",
        "# Step 9: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled_scaled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
        ")\n",
        "\n",
        "# Step 10: Initialize CatBoost Model\n",
        "# Removed cat_features as data is scaled and encoded\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    eval_metric='AUC',\n",
        "    random_state=42,\n",
        "    verbose=100,\n",
        "    early_stopping_rounds=50\n",
        ")\n",
        "\n",
        "# Step 11: Train CatBoost\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
        "\n",
        "# Step 12: Evaluate Model\n",
        "y_pred = cat_model.predict(X_test)\n",
        "y_proba = cat_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\n=== CatBoost Evaluation ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# ===============================\n",
        "# Optional: Stacking Ensemble\n",
        "# ===============================\n",
        "rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "estimators = [('cb', cat_model), ('rf', rf), ('gb', gb)]\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=CatBoostClassifier(iterations=500, learning_rate=0.05, depth=6, verbose=0, random_state=42)\n",
        ")\n",
        "\n",
        "# Train stacking ensemble\n",
        "stack_model.fit(X_train, y_train)\n",
        "y_stack_pred = stack_model.predict(X_test)\n",
        "y_stack_proba = stack_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\n=== Stacking Ensemble Evaluation ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_stack_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_stack_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_stack_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_stack_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_stack_proba))"
      ],
      "metadata": {
        "id": "dzko3IEOix86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6768dd52",
        "outputId": "403aa76f-8499-4fcb-d030-703ef9236153"
      },
      "source": [
        "%pip install category_encoders imbalanced-learn catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost, category_encoders\n",
            "Successfully installed catboost-1.2.8 category_encoders-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code interacts with all the attributes (columns) in the dataset through several data preprocessing and modeling steps. Here's a breakdown of how the code interacts with the data's attributes:\n",
        "\n",
        "Loading the Data: The first interaction is loading the dataset from the specified file path into a pandas DataFrame.\n",
        "Initial Cleanup: The code drops specific columns (Patient ID, Patient Name) that are not relevant for the prediction task.\n",
        "Separating Attribute Types: Attributes are separated into numerical and categorical types to apply different preprocessing techniques.\n",
        "Handling Missing Values:\n",
        "For numerical attributes, missing values are imputed using the K-Nearest Neighbors (KNN) imputer, which estimates missing values based on the values of their nearest neighbors.\n",
        "For categorical attributes, missing values are filled with the mode (most frequent value) of each column.\n",
        "Feature Engineering: New attributes are created based on existing ones:\n",
        "Age_group is created by categorizing the Age attribute into bins.\n",
        "Hypertension_x_Age is created by multiplying the Hypertension and Age attributes.\n",
        "Encoding Categorical Attributes: Categorical attributes (including the newly engineered Age_group) are transformed into numerical representations using Target Encoding. This replaces each category with the mean of the target variable for that category.\n",
        "Separating Features and Target: The target attribute (Diagnosis) is separated from the feature attributes (X) that will be used for training the models.\n",
        "Handling Class Imbalance: SMOTENC is applied to the features and target to create synthetic samples for the minority class. This is done before scaling, using the indices of the original categorical columns to guide the synthesis process.\n",
        "Scaling Features: The numerical feature attributes (which now include the encoded categorical features) are scaled using StandardScaler to have zero mean and unit variance. This is important for distance-based algorithms and can improve the performance of some models.\n",
        "Splitting Data: The scaled feature attributes and the resampled target attribute are split into training and testing sets.\n",
        "Model Training: The training data (including all preprocessed attributes) is used to train the CatBoost model and the Stacking Ensemble model.\n",
        "Model Evaluation: The trained models are used to make predictions on the test data, and the performance is evaluated using various metrics.\n",
        "In essence, the code interacts with all attributes by cleaning, transforming, and preparing them for use in the machine learning models. The specific interaction depends on whether an attribute is numerical or categorical and the stage of the pipeline."
      ],
      "metadata": {
        "id": "JdicOVdckXSu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4cd01a45",
        "outputId": "2bceaf58-2b85-428f-d17a-8f6c2a21b1cd"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define the number of folds\n",
        "n_splits = 5\n",
        "\n",
        "# Initialize Stratified K-Fold cross-validator\n",
        "# StratifiedKFold is used to maintain the percentage of samples for each class\n",
        "# as in the original dataset, which is important for imbalanced datasets.\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation for CatBoost model\n",
        "# We use the scaled resampled data (X_resampled_scaled, y_resampled)\n",
        "# The scoring metric is 'roc_auc' as used in the model training\n",
        "cv_scores_catboost = cross_val_score(\n",
        "    cat_model,\n",
        "    X_resampled_scaled,\n",
        "    y_resampled,\n",
        "    cv=skf,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1 # Use all available CPU cores\n",
        ")\n",
        "\n",
        "print(f\"\\n=== CatBoost Cross-validation (AUC) ===\")\n",
        "print(f\"AUC scores for each fold: {cv_scores_catboost}\")\n",
        "print(f\"Mean AUC: {cv_scores_catboost.mean():.4f}\")\n",
        "print(f\"Standard deviation of AUC: {cv_scores_catboost.std():.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cat_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2852487150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# The scoring metric is 'roc_auc' as used in the model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m cv_scores_catboost = cross_val_score(\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcat_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mX_resampled_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_resampled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cat_model' is not defined"
          ]
        }
      ]
    }
  ]
}