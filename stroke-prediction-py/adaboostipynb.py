# -*- coding: utf-8 -*-
"""AdaBoostipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mehdl8Re7gAb3Ev1vH5l8OUGtDStWar1
"""

!pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn

# 1. Install required packages (if not already installed)
# pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn

# 2. Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.combine import SMOTEENN
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, RocCurveDisplay

from google.colab import files
uploaded = files.upload()

# 2. Load dataset
df = pd.read_csv("stroke_prediction_dataset.csv")

# 3. Drop unnecessary columns
df.drop(columns=["Patient.ID", "Patient.Name"], inplace=True, errors='ignore')

# 4. Handle missing values
df.dropna(inplace=True)  # or you can use imputation

# 5. Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# 6. Split features and target
X = df.drop("Diagnosis", axis=1)
y = df["Diagnosis"]

# 7. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 8. Balance data with SMOTEENN
sm = SMOTEENN(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

# 9. Standardize numeric features
scaler = StandardScaler()
X_train_res = scaler.fit_transform(X_train_res)
X_test = scaler.transform(X_test)

# 10. Train AdaBoost model
model = AdaBoostClassifier(n_estimators=50, random_state=42)
model.fit(X_train_res, y_train_res)

# 11. Predictions
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# 12. Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("AdaBoost Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# 13. Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.preprocessing import LabelBinarizer

# Binarize y_test if it's not already in 0/1
lb = LabelBinarizer()
y_test_bin = lb.fit_transform(y_test).ravel()  # Make sure it's 1D
y_prob = model.predict_proba(X_test)[:, 1]     # Probabilities for the positive class

# ROC Curve and AUC
fpr, tpr, _ = roc_curve(y_test_bin, y_prob)
roc_auc = roc_auc_score(y_test_bin, y_prob)

plt.figure()
plt.plot(fpr, tpr, color='orange', lw=2, label=f"ROC Curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - AdaBoost")
plt.legend(loc="lower right")
plt.show()