# -*- coding: utf-8 -*-
"""PilotTest_03.01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lOm-UadkRmWqO-7eO8LRJ-ytqGVS0B1q
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use('ggplot')
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline
from sklearn.preprocessing import (StandardScaler,
                                   LabelEncoder,
                                   OneHotEncoder)
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import (classification_report, accuracy_score,
                             auc,
                             precision_score,
                             recall_score,
                             f1_score,
                             roc_auc_score,
                             confusion_matrix)
from sklearn.model_selection import (GridSearchCV,
                                     StratifiedKFold,
                                     cross_val_score)
from sklearn.decomposition import PCA
from umap import UMAP
import pylab as pl
from imblearn.datasets import make_imbalance
from imblearn.under_sampling import (RandomUnderSampler,
                                     ClusterCentroids,
                                     TomekLinks,
                                     NeighbourhoodCleaningRule,
                                     EditedNearestNeighbours,
                                     NearMiss)


from imblearn.over_sampling import (SMOTE,
                                    ADASYN)
from sklearn.ensemble import (RandomForestClassifier,
                              AdaBoostClassifier,
                              GradientBoostingClassifier)
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('stroke_prediction_dataset.csv')
df.head()

df.info()

df.describe().T

import missingno as msno

msno.matrix(df)

msno.bar(df, sort = 'descending')

df['Symptoms'].fillna('Unknown', inplace=True)  # You can also use 'No Symptoms

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder

label_encoders = {}

for col in ['Marital Status', 'Work Type', 'Residence Type', 'Alcohol Intake',	'Physical Activity', 'Diagnosis']:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Store encoder if needed for inverse transform

# Print the column names of the DataFrame to check for typos or missing columns
print(df.columns)

# After checking the output, correct the column names in the sns.countplot calls
# For example, if the column is named 'Gender' instead of 'gender', change the code to:
# sns.countplot(ax=axes[0,0],data=df,x='Gender')

fig,axes = plt.subplots(4,2,figsize = (16,16))
sns.set_style('whitegrid')
fig.suptitle("Count plot for various categorical features")

# Replace 'gender' with the correct column name if necessary
sns.countplot(ax=axes[0,0],data=df,x='Gender')
sns.countplot(ax=axes[0,1],data=df,x='Hypertension')
sns.countplot(ax=axes[1,0],data=df,x='Heart Disease')
sns.countplot(ax=axes[1,1],data=df,x='Marital Status')
sns.countplot(ax=axes[2,0],data=df,x='Work Type')
sns.countplot(ax=axes[2,1],data=df,x='Residence Type')
sns.countplot(ax=axes[3,0],data=df,x='Smoking Status')
sns.countplot(ax=axes[3,1],data=df,x='Diagnosis')

plt.show()

list_col=['Smoking Status','Work Type','Residence Type','Gender']
for col in list_col:
    print('{} :{} ' . format(col.upper(),df[col].unique()))

fig = px.box(data_frame = df,
            x = "Average Glucose Level",
            width = 800,
            height = 300)
fig.update_layout({"template":"plotly_dark"})
fig.show()

# binning method
df['bmi_cat'] = pd.cut(df['Body Mass Index (BMI)'], bins = [0, 19, 25,30,10000], labels = ['Underweight', 'Ideal', 'Overweight', 'Obesity'])
df['age_cat'] = pd.cut(df['Age'], bins = [0,13,18, 45,60,200], labels = ['Children', 'Teens', 'Adults','Mid Adults','Elderly'])
df['glucose_cat'] = pd.cut(df['Average Glucose Level'], bins = [0,90,160,230,500], labels = ['Low', 'Normal', 'High', 'Very High'])

sns.countplot(x='Diagnosis', data=df)

# Corrected column names to match the DataFrame
cat_cols = ["Gender","Hypertension","Heart Disease","Marital Status","Work Type","Residence Type","Smoking Status","Diagnosis"]
cont_cols = ["Age","Average Glucose Level","Body Mass Index (BMI)"]

cr = df[cont_cols].corr()
plt.figure(figsize = (10,10))
sns.heatmap(cr,cmap="viridis", annot = True)
plt.show()

bmi = list(df['Body Mass Index (BMI)'].values)
hist_data = [bmi]
group_labels = ["Body Mass Index (BMI)"]
colors = ['Red']
fig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)
fig.show()

df['Gender'].value_counts()

print("The shape before removing the BMI outliers : ",df.shape)

df.drop(df[df['Body Mass Index (BMI)'] > 47].index, inplace = True)
print("The shape after removing the BMI outliers : ",df.shape)

bmi = list(df['Body Mass Index (BMI)'].values)
hist_data = [bmi]
group_labels = ["Body Mass Index (BMI)"]
colors = ['Red']
fig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)
fig.show()

from sklearn.preprocessing import LabelEncoder

object_cols = ["Gender","Marital Status","Work Type","Residence Type","Smoking Status"]
label_encoder = LabelEncoder()
for col in object_cols:
    label_encoder.fit(df[col])
    df[col] = label_encoder.transform(df[col])
df.head()

df.head()

df.drop(['bmi_cat', 'age_cat', 'glucose_cat'], axis=1, inplace=True)

df = df.drop(['Patient ID', 'Patient Name'], axis=1)

df.head()

from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming df is your DataFrame after previous operations

# Identify columns with 'object' dtype
object_cols_after_preprocessing = df.select_dtypes(include='object').columns
print(f"Object columns before final encoding: {list(object_cols_after_preprocessing)}")

# Apply Label Encoding to any remaining object columns
label_encoders_final = {}
for col in object_cols_after_preprocessing:
    # Check if the column is not 'Diagnosis', as 'Diagnosis' is the target variable
    if col != 'Diagnosis':
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders_final[col] = le
        print(f"Encoded column: {col}")


# Verify dtypes after encoding
print("\nData types after final encoding:")
print(df.dtypes)

# Now apply SMOTE
sampler = SMOTE(random_state = 42)
X = df.drop(['Diagnosis'],axis=1)
y = df[['Diagnosis']]

# Ensure X and y are in the correct format (SMOTE expects numpy arrays or pandas DataFrames)
# X is already a DataFrame. y is a DataFrame, but SMOTE's fit_resample expects a 1D array for y
# You were already using .values.ravel(), which is correct for getting the numpy array
X_resampled, y_resampled = sampler.fit_resample(X,y['Diagnosis'].values.ravel())

# Convert the resampled y back to a DataFrame for plotting
y_resampled_df = pd.DataFrame({'Diagnosis': y_resampled})

# Plot the distribution of the resampled target variable
sns.countplot(data = y_resampled_df, x = 'Diagnosis', y= None)
plt.show()

from imblearn.over_sampling import SMOTE
sampler = SMOTE(random_state = 42)
X = df.drop(['Diagnosis'],axis=1)
y = df[['Diagnosis']]
X,y= sampler.fit_resample(X,y['Diagnosis'].values.ravel())
y = pd.DataFrame({'Diagnosis':y})
sns.countplot(data = y, x = 'Diagnosis', y= None)
plt.show()

df.head()

df = pd.concat([X,y],axis = 1)
df.head()

X = df.drop('Diagnosis', axis=1)
y = df['Diagnosis']
X_encoded = pd.get_dummies(X, columns=['Gender', 'Marital Status', 'Work Type', 'Residence Type', 'Smoking Status'])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

!pip install catboost
from sklearn.ensemble import VotingClassifier
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
xgb_classifier = xgb.XGBClassifier()
lgb_classifier = lgb.LGBMClassifier()
catboost_classifier = CatBoostClassifier()

voting_classifier = VotingClassifier(
    estimators=[
        ('xgb', xgb_classifier),
        ('lgb', lgb_classifier),
        ('catboost', catboost_classifier)
    ],
    voting='soft'
)
voting_classifier.fit(X_train, y_train)

y_pred = voting_classifier.predict(X_test)

train_accuracy = voting_classifier.score(X_train, y_train)
print(f"Training Accuracy of Voting Classifier is {train_accuracy:.2f}")

conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix :-")
print(conf_matrix)

class_report = classification_report(y_test, y_pred)
print("Classification Report :-")
print(class_report)